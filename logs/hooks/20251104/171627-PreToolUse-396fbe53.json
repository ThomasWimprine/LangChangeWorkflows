{"session_id":"396fbe53-cba7-45be-89d9-14577685964b","transcript_path":"/home/thomas/.claude/projects/-home-thomas-Repositories-LangChangeWorkflows/396fbe53-cba7-45be-89d9-14577685964b.jsonl","cwd":"/home/thomas/Repositories/LangChangeWorkflows","permission_mode":"default","hook_event_name":"PreToolUse","tool_name":"Write","tool_input":{"file_path":"/home/thomas/Repositories/LangChangeWorkflows/lessons/01-hello-langgraph/task002_nodes.py","content":"#!/usr/bin/env python3\n\"\"\"\ntask002_nodes.py - LangGraph nodes for TASK002 workflow integration\n\nThis module provides LangGraph nodes that integrate the TASK002 workflow logic\nfrom draft-002.py. These nodes handle:\n1. Collecting TASK001 outputs and extracting questions\n2. Deduplicating questions using Claude\n3. Processing questions through an architect agent\n\nEach node accepts and returns the workflow state, updating it with results.\n\"\"\"\nfrom __future__ import annotations\n\nimport json\nimport os\nimport sys\nimport time\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Tuple, TypedDict\n\n# Add GitWorkflow scripts path to import from draft-002.py\nGITWORKFLOW_SCRIPTS = Path(__file__).resolve().parent.parent.parent / \"GitWorkflow\" / \"scripts\"\nif GITWORKFLOW_SCRIPTS.exists():\n    sys.path.insert(0, str(GITWORKFLOW_SCRIPTS.parent))\n\n# Try to import from draft-002.py helper functions\ntry:\n    from scripts.draft_002 import (\n        _collect_task001_data,\n        _dedup_questions_via_model,\n        _build_task002_user_instruction,\n        _extract_text_blocks_from_result,\n        _get_custom_id,\n        _extract_first_json_object,\n        _extract_fenced_json,\n        _next_P,\n        _next_Q,\n        load_agent_text,\n        AGENT_DIRS,\n        MODEL_ID,\n    )\n    DRAFT002_AVAILABLE = True\nexcept ImportError:\n    DRAFT002_AVAILABLE = False\n    print(\"Warning: Could not import from draft-002.py. Using fallback implementations.\")\n\n# Fallback implementations if draft-002.py is not available\nif not DRAFT002_AVAILABLE:\n    MODEL_ID = \"claude-sonnet-4-5\"\n    AGENT_DIRS = [Path(os.path.expanduser(\"~/.claude/agents\"))]\n\n    def _seq_path() -> Path:\n        return Path(\"prp/prp_seq.json\")\n\n    def _read_seq() -> dict:\n        p = _seq_path()\n        if not p.exists():\n            p.parent.mkdir(parents=True, exist_ok=True)\n            data = {\"P\": 0, \"Q\": {\"002\": 0}}\n            p.write_text(json.dumps(data, separators=(\",\", \":\")), encoding=\"utf-8\")\n            return data\n        try:\n            return json.loads(p.read_text(encoding=\"utf-8\"))\n        except Exception:\n            return {\"P\": 0, \"Q\": {\"002\": 0}}\n\n    def _write_seq(data: dict) -> None:\n        p = _seq_path()\n        tmp = p.with_suffix(\".tmp\")\n        p.parent.mkdir(parents=True, exist_ok=True)\n        tmp.write_text(json.dumps(data, separators=(\",\", \":\")), encoding=\"utf-8\")\n        tmp.replace(p)\n\n    def _next_P() -> int:\n        data = _read_seq()\n        data[\"P\"] = int(data.get(\"P\", 0)) + 1\n        _write_seq(data)\n        return data[\"P\"]\n\n    def _next_Q(task: str = \"002\") -> int:\n        data = _read_seq()\n        q = data.get(\"Q\") or {}\n        curr = int((q.get(task) or 0)) + 1\n        q[task] = curr\n        data[\"Q\"] = q\n        _write_seq(data)\n        return curr\n\n    def load_agent_text(name: str) -> str:\n        \"\"\"Load agent system prompt text from registry directories.\"\"\"\n        fname = f\"{name}.md\"\n        for base in AGENT_DIRS:\n            p = base / fname\n            if p.exists():\n                return p.read_text(encoding=\"utf-8\", errors=\"replace\")\n        raise FileNotFoundError(f\"Agent file not found for '{name}' in: {', '.join(str(d) for d in AGENT_DIRS)}\")\n\n    def _collect_task001_data() -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n        \"\"\"Collect TASK001 drafts and extract questions.\"\"\"\n        draft_dir = Path(\"prp/drafts\")\n        if not draft_dir.exists():\n            return [], []\n\n        seen_paths: set[str] = set()\n        drafts: List[Path] = []\n\n        # New naming (P-###-T-001.json)\n        for p in sorted(draft_dir.glob(\"P-*-T-001*.json\"), key=lambda q: str(q)):\n            sp = str(p)\n            if sp not in seen_paths:\n                seen_paths.add(sp)\n                drafts.append(p)\n\n        # Legacy naming (*task001*.json)\n        for p in sorted(draft_dir.glob(\"*task001*.json\"), key=lambda q: str(q)):\n            sp = str(p)\n            if sp not in seen_paths:\n                seen_paths.add(sp)\n                drafts.append(p)\n\n        responses: List[Dict[str, Any]] = []\n        questions: List[Dict[str, Any]] = []\n\n        for p in drafts:\n            try:\n                root = json.loads(p.read_text(encoding=\"utf-8\"))\n            except Exception:\n                continue\n\n            if not isinstance(root, dict):\n                continue\n\n            content = root.get(\"content\") if isinstance(root.get(\"content\"), dict) else None\n            if not isinstance(content, dict):\n                continue\n\n            # Heuristic: consider only TASK001-like content shapes\n            is_task001_shape = (\n                (\"atomicity\" in content or \"proposed_tasks\" in content) and\n                (isinstance(content.get(\"Questions\"), list) or isinstance(content.get(\"questions\"), list))\n            )\n            if not is_task001_shape:\n                continue\n\n            responses.append({\"file\": p.name, \"content\": content})\n\n            qlist = None\n            if isinstance(content.get(\"Questions\"), list):\n                qlist = content.get(\"Questions\")\n            elif isinstance(content.get(\"questions\"), list):\n                qlist = content.get(\"questions\")\n\n            if isinstance(qlist, list):\n                for q in qlist:\n                    if isinstance(q, dict) and isinstance(q.get(\"question\"), str):\n                        questions.append({\n                            \"question\": q.get(\"question\"),\n                            \"agent\": (q.get(\"agent\") if isinstance(q.get(\"agent\"), str) else \"\"),\n                            \"source_file\": p.name,\n                        })\n\n        # Deterministic order across runs\n        questions.sort(key=lambda d: (d.get(\"agent\") or \"\", d.get(\"question\") or \"\", d.get(\"source_file\") or \"\"))\n        responses.sort(key=lambda d: d.get(\"file\") or \"\")\n\n        return responses, questions\n\n    def _extract_text_blocks_from_result(item) -> list[str]:\n        \"\"\"Normalize Anthropic batch result item into a list of text blocks.\"\"\"\n        if isinstance(item, str):\n            try:\n                obj = json.loads(item)\n            except Exception:\n                return [item]\n            result = obj.get(\"result\") if isinstance(obj, dict) else None\n            message = (result or {}).get(\"message\") if isinstance(result, dict) else None\n            content = (message or {}).get(\"content\", []) if isinstance(message, dict) else []\n            blocks: list[str] = []\n            for c in content:\n                if isinstance(c, dict) and c.get(\"type\") == \"text\":\n                    blocks.append(c.get(\"text\", \"\"))\n            return blocks\n        try:\n            result = getattr(item, \"result\", None)\n            message = getattr(result, \"message\", None)\n            content = getattr(message, \"content\", [])\n            blocks: list[str] = []\n            for c in content:\n                if hasattr(c, \"type\") and getattr(c, \"type\") == \"text\":\n                    blocks.append(getattr(c, \"text\", \"\"))\n                elif isinstance(c, dict) and c.get(\"type\") == \"text\":\n                    blocks.append(c.get(\"text\", \"\"))\n            return blocks\n        except Exception:\n            return []\n\n    def _get_custom_id(item) -> str | None:\n        \"\"\"Extract custom_id from batch item.\"\"\"\n        try:\n            cid = getattr(item, \"custom_id\", None)\n            if cid:\n                return cid\n        except Exception:\n            pass\n        if isinstance(item, str):\n            try:\n                obj = json.loads(item)\n                return obj.get(\"custom_id\")\n            except Exception:\n                return None\n        return None\n\n    def _extract_first_json_object(s: str):\n        \"\"\"Return the first parseable JSON object found in the string.\"\"\"\n        start = s.find(\"{\")\n        while start != -1:\n            depth = 0\n            for i in range(start, len(s)):\n                ch = s[i]\n                if ch == \"{\":\n                    depth += 1\n                elif ch == \"}\":\n                    depth -= 1\n                    if depth == 0:\n                        candidate = s[start:i+1]\n                        try:\n                            return json.loads(candidate)\n                        except Exception:\n                            break\n            start = s.find(\"{\", start + 1)\n        return None\n\n    def _extract_fenced_json(s: str):\n        \"\"\"Return JSON parsed from a ```json fenced block.\"\"\"\n        import re as _re\n        pattern = _re.compile(r\"```json\\s*(.*?)```\", _re.DOTALL | _re.IGNORECASE)\n        m = pattern.search(s)\n        if not m:\n            return None\n        block = m.group(1).strip()\n        try:\n            return json.loads(block)\n        except Exception:\n            return block\n\n    def _dedup_questions_via_model(client: Any, model: str, max_tokens: int, questions: List[Dict[str, Any]]) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:\n        \"\"\"Ask the model to deduplicate questions.\"\"\"\n        src = sorted([\n            {\n                \"question\": (q.get(\"question\") or \"\").strip(),\n                \"agent\": (q.get(\"agent\") or \"\").strip(),\n                \"source_file\": (q.get(\"source_file\") or \"\").strip(),\n            }\n        for q in questions\n        if isinstance(q, dict) and isinstance(q.get(\"question\"), str) and (q.get(\"question\") or \"\").strip()\n        ], key=lambda d: (d[\"question\"], d[\"agent\"], d[\"source_file\"]))\n\n        input_json = json.dumps({\"questions\": src}, indent=2, sort_keys=True, ensure_ascii=False)\n        user_text = (\n            \"Task: Deduplicate semantically equivalent questions.\\n\\n\"\n            \"Instructions:\\n\"\n            \"- Normalize whitespace and punctuation; treat questions with the same meaning as duplicates.\\n\"\n            \"- Produce a canonical phrasing for each group.\\n\"\n            \"- Aggregate all agents and source_files that raised the duplicate question.\\n\\n\"\n            \"Input JSON:\\n\" + input_json + \"\\n\\n\"\n            \"Output JSON schema (return JSON only):\\n\"\n            \"{\\n\"\n            \"  \\\"questions\\\": [\\n\"\n            \"    { \\\"question\\\": \\\"...\\\", \\\"agents\\\": [\\\"...\\\"], \\\"source_files\\\": [\\\"...\\\"] }\\n\"\n            \"  ]\\n\"\n            \"}\\n\"\n        )\n\n        req = {\n            \"custom_id\": \"dedup-questions\",\n            \"params\": {\n                \"model\": model,\n                \"max_tokens\": int(max_tokens),\n                \"temperature\": 0.2,\n                \"messages\": [\n                    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": user_text}]}\n                ],\n            },\n        }\n\n        batch = client.messages.batches.create(requests=[req])\n        while True:\n            b = client.messages.batches.retrieve(batch.id)\n            if b.processing_status in (\"ended\", \"failed\", \"expired\"):\n                break\n            time.sleep(1)\n\n        items = list(client.messages.batches.results(batch.id))\n        if not items:\n            return [], {}\n\n        blocks = _extract_text_blocks_from_result(items[0])\n        combined = \"\\n\\n\".join(blocks) if blocks else \"\"\n\n        # Save raw for diagnostics\n        try:\n            raw_path = Path(\"tmp/raw/dedup-questions.txt\")\n            raw_path.parent.mkdir(parents=True, exist_ok=True)\n            raw_path.write_text(combined or \"\", encoding=\"utf-8\")\n        except Exception:\n            pass\n\n        payload = _extract_first_json_object(combined) or _extract_fenced_json(combined)\n        if isinstance(payload, str):\n            try:\n                payload = json.loads(payload)\n            except Exception:\n                pass\n\n        def _normalize_list(lst: Any) -> List[Dict[str, Any]]:\n            out: List[Dict[str, Any]] = []\n            if not isinstance(lst, list):\n                return out\n            for e in lst:\n                if isinstance(e, str):\n                    q = e.strip()\n                    if q:\n                        out.append({\"question\": q, \"agents\": [], \"source_files\": []})\n                elif isinstance(e, dict):\n                    q = (e.get(\"question\") or \"\").strip()\n                    if not q:\n                        q = (e.get(\"q\") or \"\").strip()\n                    if q:\n                        agents = [a.strip() for a in (e.get(\"agents\") or []) if isinstance(a, str) and a.strip()]\n                        srcs = [s.strip() for s in (e.get(\"source_files\") or []) if isinstance(s, str) and s.strip()]\n                        out.append({\"question\": q, \"agents\": sorted(set(agents)), \"source_files\": sorted(set(srcs))})\n            return out\n\n        dedup: List[Dict[str, Any]] = []\n        if isinstance(payload, dict):\n            out_list = payload.get(\"questions\")\n            dedup = _normalize_list(out_list)\n        elif isinstance(payload, list):\n            dedup = _normalize_list(payload)\n        else:\n            dedup = []\n\n        diag: Dict[str, Any] = {}\n        if isinstance(payload, dict):\n            diag = payload\n        elif isinstance(payload, list):\n            diag = {\"list_payload\": payload}\n\n        return dedup, diag\n\n    def _build_task002_user_instruction(template_path: str, architect: str, question_text: str, q_id: int) -> str:\n        \"\"\"Build the user prompt for TASK002 QA per question.\"\"\"\n        t = Path(template_path).read_text(encoding=\"utf-8\") if Path(template_path).exists() else \"\"\n        qid_str = f\"T-002-Q-{q_id:03d}\"\n        example = (\n            '{\\n'\n            '  \"outputs\": { \"draft_file\": \"P-XXX-T-002-Q-YYY.json\" },\\n'\n            '  \"content\": {\\n'\n            f'    \"agent_name\": \"{architect}\",\\n'\n            f'    \"id\": \"{qid_str}\",\\n'\n            f'    \"question\": {json.dumps(question_text)},\\n'\n            '    \"answer\": \"...\",\\n'\n            '    \"citation\": [\"...\"]\\n'\n            '  }\\n'\n            '}'\n        )\n        return (\n            \"Task: STRICT TEMPLATE COMPLIANCE â€” Answer the question using TASK002 template EXACTLY.\\n\\n\"\n            \"Rules:\\n\"\n            \"- Return JSON only, no prose\\n\"\n            \"- Do not add or remove keys\\n\"\n            \"- Preserve key order and structure\\n\"\n            \"- Replace only placeholder/example values\\n\"\n            \"- Copy the question text exactly into content.question\\n\"\n            \"- Include citations to repo_context paths or entries in TASK001 RESPONSES\\n\\n\"\n            f\"Question:\\n{question_text}\\n\\n\"\n            f\"Constraints:\\n- agent_name MUST be '{architect}'\\n- id MUST be '{qid_str}'\\n\\n\"\n            f\"JSON Template (copy structure exactly):\\n{t}\\n\\n\"\n            \"Output wrapper (start your response with '{\\\"outputs\\\"'):\\n\"\n            f\"{example}\\n\"\n        )\n\n\n# State schema extension for TASK002\nclass Task002State(TypedDict, total=False):\n    \"\"\"Extended state for TASK002 workflow nodes.\n\n    This extends the base workflow state with TASK002-specific fields.\n    \"\"\"\n    # Existing state fields from TASK001 (assumed)\n    feature_description: str\n    model: str\n    max_tokens: int\n    architect_agent: str\n    template_path: str\n\n    # TASK002-specific state fields\n    task001_responses: List[Dict[str, Any]]  # List of TASK001 draft contents\n    raw_questions: List[Dict[str, Any]]       # Extracted questions before dedup\n    deduped_questions: List[Dict[str, Any]]   # Deduplicated questions\n    task002_responses: List[Dict[str, Any]]   # Architect answers\n\n    # API client and configuration\n    anthropic_client: Any  # Anthropic API client\n    dedup_max_tokens: int  # Max tokens for dedup pass\n\n\n# ============================================================================\n# TASK002 LangGraph Nodes\n# ============================================================================\n\ndef collect_questions_node(state: Task002State) -> Task002State:\n    \"\"\"Node 1: Collect TASK001 outputs and extract questions.\n\n    This node:\n    1. Scans prp/drafts/ for TASK001 output files\n    2. Extracts questions from each draft\n    3. Updates state with responses and raw questions\n\n    Args:\n        state: Current workflow state\n\n    Returns:\n        Updated state with task001_responses and raw_questions populated\n    \"\"\"\n    print(\"[collect_questions_node] Starting question collection...\")\n\n    try:\n        # Collect TASK001 data using imported helper\n        responses, questions = _collect_task001_data()\n\n        print(f\"[collect_questions_node] Found {len(responses)} TASK001 drafts\")\n        print(f\"[collect_questions_node] Extracted {len(questions)} raw questions\")\n\n        # Update state\n        state[\"task001_responses\"] = responses\n        state[\"raw_questions\"] = questions\n\n        # Log sample questions for debugging\n        if questions:\n            print(f\"[collect_questions_node] Sample questions:\")\n            for i, q in enumerate(questions[:3], 1):\n                print(f\"  {i}. {q.get('question', '')[:80]}...\")\n\n        return state\n\n    except Exception as e:\n        print(f\"[collect_questions_node] ERROR: {e}\")\n        import traceback\n        traceback.print_exc()\n        # Return state with empty lists on error\n        state[\"task001_responses\"] = []\n        state[\"raw_questions\"] = []\n        return state\n\n\ndef deduplicate_questions_node(state: Task002State) -> Task002State:\n    \"\"\"Node 2: Deduplicate questions using Claude.\n\n    This node:\n    1. Takes raw questions from state\n    2. Uses Claude to deduplicate semantically similar questions\n    3. Saves deduplicated questions to prp/drafts/P-###-T-002-DEDUPE.json\n    4. Updates state with deduped_questions\n\n    Args:\n        state: Current workflow state with raw_questions\n\n    Returns:\n        Updated state with deduped_questions populated\n    \"\"\"\n    print(\"[deduplicate_questions_node] Starting question deduplication...\")\n\n    questions = state.get(\"raw_questions\", [])\n\n    if not questions:\n        print(\"[deduplicate_questions_node] No questions to deduplicate\")\n        state[\"deduped_questions\"] = []\n        return state\n\n    try:\n        client = state.get(\"anthropic_client\")\n        if not client:\n            print(\"[deduplicate_questions_node] ERROR: No Anthropic client in state\")\n            state[\"deduped_questions\"] = questions  # Fallback: use raw questions\n            return state\n\n        model = state.get(\"model\", MODEL_ID)\n        dedup_max_tokens = state.get(\"dedup_max_tokens\", 2048)\n\n        print(f\"[deduplicate_questions_node] Deduplicating {len(questions)} questions via Claude...\")\n\n        # Call dedup helper\n        dedup_list, dedup_payload = _dedup_questions_via_model(\n            client=client,\n            model=model,\n            max_tokens=dedup_max_tokens,\n            questions=questions\n        )\n\n        # Fallback: local deduplication if model returns empty\n        if not dedup_list:\n            print(\"[deduplicate_questions_node] Model dedup failed, using local fallback...\")\n            seen = {}\n            import re as _re\n\n            def _norm(s: str) -> str:\n                s = (s or \"\").strip().lower()\n                s = _re.sub(r\"\\s+\", \" \", s)\n                s = _re.sub(r\"[\\.?!,;:]+$\", \"\", s)\n                return s\n\n            for q in questions:\n                qt = _norm(q.get(\"question\") or \"\")\n                if not qt:\n                    continue\n                entry = seen.setdefault(qt, {\n                    \"question\": q.get(\"question\") or \"\",\n                    \"agents\": set(),\n                    \"source_files\": set()\n                })\n                a = (q.get(\"agent\") or \"\").strip()\n                if a:\n                    entry[\"agents\"].add(a)\n                s = (q.get(\"source_file\") or \"\").strip()\n                if s:\n                    entry[\"source_files\"].add(s)\n\n            dedup_list = [\n                {\n                    \"question\": v[\"question\"],\n                    \"agents\": sorted(v[\"agents\"]),\n                    \"source_files\": sorted(v[\"source_files\"])\n                }\n                for v in seen.values()\n            ]\n\n        # Save dedup file under prp/drafts with next P and marker T-002-DEDUPE\n        P_d = _next_P()\n        dedup_path = Path(\"prp/drafts\") / f\"P-{P_d:03d}-T-002-DEDUPE.json\"\n        dedup_path.parent.mkdir(parents=True, exist_ok=True)\n\n        to_save = {\n            \"outputs\": {\"draft_file\": str(dedup_path)},\n            \"content\": {\"questions\": dedup_list},\n            \"diagnostics\": dedup_payload if isinstance(dedup_payload, dict) else {}\n        }\n\n        dedup_path.write_text(json.dumps(to_save, indent=2), encoding=\"utf-8\")\n        print(f\"[deduplicate_questions_node] Saved dedup file -> {dedup_path}\")\n        print(f\"[deduplicate_questions_node] Reduced {len(questions)} to {len(dedup_list)} unique questions\")\n\n        # Update state\n        state[\"deduped_questions\"] = dedup_list\n\n        return state\n\n    except Exception as e:\n        print(f\"[deduplicate_questions_node] ERROR: {e}\")\n        import traceback\n        traceback.print_exc()\n        # Fallback: use raw questions\n        state[\"deduped_questions\"] = questions\n        return state\n\n\ndef process_questions_node(state: Task002State) -> Task002State:\n    \"\"\"Node 3: Batch process questions through architect agent.\n\n    This node:\n    1. Takes deduplicated questions from state\n    2. Builds a batch request to Claude with architect system prompt\n    3. Processes all questions in a single batch for efficiency\n    4. Saves each answer as P-###-T-002-Q-###.json\n    5. Updates state with task002_responses\n\n    Args:\n        state: Current workflow state with deduped_questions\n\n    Returns:\n        Updated state with task002_responses populated\n    \"\"\"\n    print(\"[process_questions_node] Starting question processing...\")\n\n    dedup_questions = state.get(\"deduped_questions\", [])\n\n    if not dedup_questions:\n        print(\"[process_questions_node] No questions to process\")\n        state[\"task002_responses\"] = []\n        return state\n\n    try:\n        client = state.get(\"anthropic_client\")\n        if not client:\n            print(\"[process_questions_node] ERROR: No Anthropic client in state\")\n            state[\"task002_responses\"] = []\n            return state\n\n        # Get configuration from state\n        model = state.get(\"model\", MODEL_ID)\n        max_tokens = state.get(\"max_tokens\", 8192)\n        architect = state.get(\"architect_agent\", \"application-architect\")\n        template_path = state.get(\"template_path\", \"templates/prp/draft-prp-002.json\")\n\n        # Build shared system extras for caching\n        system_extras: List[dict] = []\n\n        # Load architect system prompt\n        try:\n            architect_text = load_agent_text(architect)\n            system_extras.append({\n                \"type\": \"text\",\n                \"text\": architect_text,\n                \"cache_control\": {\"type\": \"ephemeral\", \"ttl\": \"1h\"}\n            })\n        except FileNotFoundError as e:\n            print(f\"[process_questions_node] ERROR loading architect prompt: {e}\")\n            state[\"task002_responses\"] = []\n            return state\n\n        # Add TASK001 responses to system context\n        responses = state.get(\"task001_responses\", [])\n        if responses:\n            prp_json = json.dumps(\n                {\"task001_responses\": responses},\n                indent=2,\n                sort_keys=True,\n                ensure_ascii=False\n            )\n            system_extras.append({\n                \"type\": \"text\",\n                \"text\": \"TASK001 RESPONSES (JSON):\\n\" + prp_json,\n                \"cache_control\": {\"type\": \"ephemeral\", \"ttl\": \"1h\"}\n            })\n\n        # Build batch requests (one per question)\n        requests = []\n        cid_to_q: Dict[str, int] = {}\n\n        # Convert dedup format to simple question list\n        questions = [\n            {\n                \"question\": e.get(\"question\"),\n                \"agent\": \",\".join(e.get(\"agents\", [])),\n                \"source_file\": \",\".join(e.get(\"source_files\", []))\n            }\n            for e in dedup_questions\n        ]\n\n        for q_item in questions:\n            qn = str(q_item.get(\"question\") or \"\").strip()\n            if not qn:\n                continue\n\n            Qnum = _next_Q(\"002\")\n            qid_str = f\"T-002-Q-{Qnum:03d}\"\n\n            # Build user instruction for this question\n            user_text = _build_task002_user_instruction(\n                template_path, architect, qn, Qnum\n            )\n\n            req = {\n                \"custom_id\": f\"qa-Q-{Qnum:03d}\",\n                \"params\": {\n                    \"model\": model,\n                    \"max_tokens\": int(max_tokens),\n                    \"temperature\": 0.2,\n                    \"system\": system_extras,\n                    \"messages\": [\n                        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": user_text}]}\n                    ],\n                },\n            }\n\n            cid_to_q[req[\"custom_id\"]] = Qnum\n            requests.append(req)\n\n        if not requests:\n            print(\"[process_questions_node] No valid questions to process\")\n            state[\"task002_responses\"] = []\n            return state\n\n        # Submit batch\n        print(f\"[process_questions_node] Submitting batch with {len(requests)} questions...\")\n        batch = client.messages.batches.create(requests=requests)\n        print(f\"[process_questions_node] batch_id={batch.id} status={batch.processing_status}\")\n\n        # Poll for completion\n        while True:\n            b = client.messages.batches.retrieve(batch.id)\n            print(f\"[process_questions_node] poll: status={b.processing_status}\")\n            if b.processing_status in (\"ended\", \"failed\", \"expired\"):\n                break\n            time.sleep(2)\n\n        # Process results\n        items = list(client.messages.batches.results(batch.id))\n        print(f\"[process_questions_node] results_count={len(items)}\")\n\n        if not items:\n            print(\"[process_questions_node] No results returned\")\n            state[\"task002_responses\"] = []\n            return state\n\n        saved_responses = []\n\n        for it in items:\n            blocks = _extract_text_blocks_from_result(it)\n            cid = _get_custom_id(it) or \"\"\n\n            if not blocks:\n                print(f\"[process_questions_node] WARN: no text blocks for {cid or 'unknown'}\")\n                continue\n\n            combined = \"\\n\\n\".join(blocks)\n            payload = _extract_first_json_object(combined) or _extract_fenced_json(combined)\n\n            if isinstance(payload, str):\n                try:\n                    payload = json.loads(payload)\n                except Exception:\n                    pass\n\n            qnum = cid_to_q.get(cid)\n\n            if not isinstance(payload, dict):\n                # Save raw for debugging\n                label = f\"Q-{qnum:03d}\" if isinstance(qnum, int) else \"unknown\"\n                raw_out = f\"tmp/raw/task002-{label}.txt\"\n                Path(raw_out).parent.mkdir(parents=True, exist_ok=True)\n                Path(raw_out).write_text(combined, encoding=\"utf-8\")\n                print(f\"[process_questions_node] Saved raw -> {raw_out}\")\n                continue\n\n            # Coerce content-only responses into wrapper if needed\n            outs = payload.get(\"outputs\") if isinstance(payload.get(\"outputs\"), dict) else None\n            content = payload.get(\"content\") if isinstance(payload.get(\"content\"), dict) else None\n\n            if content is None:\n                looks_like_content = (\n                    isinstance(payload.get(\"answer\"), str)\n                    or isinstance(payload.get(\"agent_name\"), str)\n                    or isinstance(payload.get(\"id\"), str)\n                )\n                if looks_like_content:\n                    content = payload\n                    payload = {\"content\": content}\n\n            if not isinstance(outs, dict):\n                outs = {}\n                payload[\"outputs\"] = outs\n\n            if not isinstance(qnum, int):\n                print(f\"[process_questions_node] WARN: missing Q mapping for {cid}\")\n                continue\n\n            # Enforce content fields\n            try:\n                if isinstance(content, dict):\n                    content.setdefault(\"agent_name\", architect)\n                    content[\"agent_name\"] = architect\n                    content.setdefault(\"id\", f\"T-002-Q-{qnum:03d}\")\n                    content[\"id\"] = f\"T-002-Q-{qnum:03d}\"\n            except Exception:\n                pass\n\n            # Compute final path\n            P = _next_P()\n            final = Path(\"prp/drafts\") / f\"P-{P:03d}-T-002-Q-{qnum:03d}.json\"\n\n            try:\n                outs[\"draft_file\"] = str(final)\n            except Exception:\n                payload[\"outputs\"] = {\"draft_file\": str(final)}\n\n            if isinstance(content, dict):\n                final.parent.mkdir(parents=True, exist_ok=True)\n                Path(final).write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n                print(f\"[process_questions_node] Saved draft -> {final}\")\n                saved_responses.append(payload)\n            else:\n                # Invalid content; save diagnostics\n                out = Path(\"tmp/raw\") / f\"task002-Q-{qnum:03d}-invalid.json\"\n                out.parent.mkdir(parents=True, exist_ok=True)\n                out.write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n                print(f\"[process_questions_node] WARN: invalid JSON for Q-{qnum:03d}. Saved -> {out}\")\n\n        print(f\"[process_questions_node] Successfully processed {len(saved_responses)} questions\")\n\n        # Update state\n        state[\"task002_responses\"] = saved_responses\n\n        return state\n\n    except Exception as e:\n        print(f\"[process_questions_node] ERROR: {e}\")\n        import traceback\n        traceback.print_exc()\n        state[\"task002_responses\"] = []\n        return state\n\n\n# ============================================================================\n# Utility function for workflow integration\n# ============================================================================\n\ndef create_task002_workflow():\n    \"\"\"Create a simple LangGraph workflow for TASK002.\n\n    This is a convenience function that creates a basic workflow with the\n    three TASK002 nodes. For integration into a larger workflow, use the\n    individual node functions directly.\n\n    Returns:\n        A compiled LangGraph workflow ready for execution\n    \"\"\"\n    from langgraph.graph import StateGraph\n\n    # Create graph with Task002State\n    workflow = StateGraph(Task002State)\n\n    # Add nodes\n    workflow.add_node(\"collect_questions\", collect_questions_node)\n    workflow.add_node(\"deduplicate_questions\", deduplicate_questions_node)\n    workflow.add_node(\"process_questions\", process_questions_node)\n\n    # Add edges\n    workflow.add_edge(\"collect_questions\", \"deduplicate_questions\")\n    workflow.add_edge(\"deduplicate_questions\", \"process_questions\")\n\n    # Set entry point\n    workflow.set_entry_point(\"collect_questions\")\n\n    # Set finish point\n    workflow.set_finish_point(\"process_questions\")\n\n    # Compile\n    return workflow.compile()\n\n\nif __name__ == \"__main__\":\n    \"\"\"Test harness for TASK002 nodes.\"\"\"\n    from dotenv import load_dotenv, find_dotenv\n    import anthropic\n\n    print(\"=== TASK002 Nodes Test Harness ===\\n\")\n\n    # Load environment\n    load_dotenv(find_dotenv(usecwd=True), override=False)\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\n    if not api_key:\n        print(\"ERROR: Set ANTHROPIC_API_KEY in environment or .env\")\n        sys.exit(1)\n\n    # Create client\n    client = anthropic.Anthropic(api_key=api_key)\n\n    # Initialize state\n    initial_state: Task002State = {\n        \"feature_description\": \"Test feature\",\n        \"model\": MODEL_ID,\n        \"max_tokens\": 8192,\n        \"architect_agent\": \"application-architect\",\n        \"template_path\": \"templates/prp/draft-prp-002.json\",\n        \"anthropic_client\": client,\n        \"dedup_max_tokens\": 2048,\n    }\n\n    # Test node 1: collect questions\n    print(\"\\n--- Testing collect_questions_node ---\")\n    state = collect_questions_node(initial_state)\n    print(f\"Collected {len(state.get('raw_questions', []))} questions\\n\")\n\n    # Test node 2: deduplicate questions\n    print(\"\\n--- Testing deduplicate_questions_node ---\")\n    state = deduplicate_questions_node(state)\n    print(f\"Deduplicated to {len(state.get('deduped_questions', []))} questions\\n\")\n\n    # Test node 3: process questions\n    print(\"\\n--- Testing process_questions_node ---\")\n    state = process_questions_node(state)\n    print(f\"Processed {len(state.get('task002_responses', []))} questions\\n\")\n\n    print(\"\\n=== Test Complete ===\")\n"}}
