{"session_id":"f0d4fbc3-a5b1-443e-8264-7550e32cfe6a","transcript_path":"/home/thomas/.claude/projects/-home-thomas-Repositories-LangChangeWorkflows/f0d4fbc3-a5b1-443e-8264-7550e32cfe6a.jsonl","cwd":"/home/thomas/Repositories/LangChangeWorkflows","permission_mode":"acceptEdits","hook_event_name":"PostToolUse","tool_name":"Write","tool_input":{"file_path":"/home/thomas/Repositories/LangChangeWorkflows/langgraph/utils/state_persistence.py","content":"\"\"\"\nState Persistence\n\nHandles ephemeral state storage for LangGraph workflows.\nState is session-only and never persisted to permanent storage for privacy.\n\nKey Features:\n- Session-only state storage (memory)\n- Optional disk cache for debugging (auto-deleted)\n- State snapshots for workflow inspection\n- Automatic cleanup on workflow completion\n\"\"\"\n\nimport logging\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime\nimport json\nfrom pathlib import Path\n\nlogger = logging.getLogger(__name__)\n\n\nclass StatePersistence:\n    \"\"\"\n    Manages ephemeral state persistence for workflows.\n\n    Privacy-First Design:\n    - State stored in memory only\n    - Optional temp disk cache for debugging (auto-cleanup)\n    - No sensitive data persisted beyond session\n    - Complete cleanup on workflow end\n    \"\"\"\n\n    def __init__(self, enable_debug_cache: bool = False):\n        \"\"\"\n        Initialize state persistence.\n\n        Args:\n            enable_debug_cache: Enable temporary disk cache for debugging\n        \"\"\"\n        self.enable_debug_cache = enable_debug_cache\n        self.cache_dir = Path(\".langgraph/state_cache\") if enable_debug_cache else None\n\n        if self.cache_dir:\n            self.cache_dir.mkdir(parents=True, exist_ok=True)\n            logger.warning(\"Debug cache enabled - state will be temporarily persisted to disk\")\n\n        self.active_states: Dict[str, Dict[str, Any]] = {}\n\n        logger.info(f\"StatePersistence initialized (debug_cache: {enable_debug_cache})\")\n\n    def save_state(self, state: Dict[str, Any]):\n        \"\"\"\n        Save workflow state (ephemeral).\n\n        Args:\n            state: Workflow state to save\n        \"\"\"\n        workflow_id = state.get(\"workflow_id\", \"unknown\")\n\n        # Store in memory\n        self.active_states[workflow_id] = {\n            **state,\n            \"last_updated\": datetime.now().isoformat()\n        }\n\n        # Optional debug cache\n        if self.enable_debug_cache and self.cache_dir:\n            self._write_debug_cache(workflow_id, state)\n\n        logger.debug(f\"State saved for workflow: {workflow_id}\")\n\n    def load_state(self, workflow_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Load workflow state from memory.\n\n        Args:\n            workflow_id: Workflow identifier\n\n        Returns:\n            Workflow state or None if not found\n        \"\"\"\n        state = self.active_states.get(workflow_id)\n\n        if state:\n            logger.debug(f\"State loaded for workflow: {workflow_id}\")\n        else:\n            logger.warning(f\"No state found for workflow: {workflow_id}\")\n\n        return state\n\n    def get_snapshot(self, workflow_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Get read-only snapshot of workflow state.\n\n        Args:\n            workflow_id: Workflow identifier\n\n        Returns:\n            Deep copy of state for inspection\n        \"\"\"\n        state = self.active_states.get(workflow_id)\n\n        if not state:\n            return None\n\n        # Return deep copy to prevent modification\n        import copy\n        return copy.deepcopy(state)\n\n    def cleanup_workflow(self, workflow_id: str):\n        \"\"\"\n        Clean up all state for completed workflow.\n\n        Args:\n            workflow_id: Workflow identifier\n        \"\"\"\n        # Remove from memory\n        if workflow_id in self.active_states:\n            del self.active_states[workflow_id]\n\n        # Remove debug cache if exists\n        if self.enable_debug_cache and self.cache_dir:\n            cache_file = self.cache_dir / f\"{workflow_id}.json\"\n            if cache_file.exists():\n                cache_file.unlink()\n\n        logger.info(f\"Cleaned up state for workflow: {workflow_id}\")\n\n    def cleanup_all(self):\n        \"\"\"\n        Clean up all active states (emergency cleanup).\n        \"\"\"\n        workflow_count = len(self.active_states)\n\n        # Clear memory\n        self.active_states.clear()\n\n        # Clear debug cache\n        if self.enable_debug_cache and self.cache_dir:\n            for cache_file in self.cache_dir.glob(\"*.json\"):\n                cache_file.unlink()\n\n        logger.info(f\"Cleaned up all states ({workflow_count} workflows)\")\n\n    def list_active_workflows(self) -> list[str]:\n        \"\"\"\n        List all active workflow IDs.\n\n        Returns:\n            List of workflow identifiers\n        \"\"\"\n        return list(self.active_states.keys())\n\n    def get_workflow_summary(self, workflow_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Get summary of workflow state (non-sensitive fields only).\n\n        Args:\n            workflow_id: Workflow identifier\n\n        Returns:\n            Summary dict with workflow status, gates, etc.\n        \"\"\"\n        state = self.active_states.get(workflow_id)\n\n        if not state:\n            return None\n\n        return {\n            \"workflow_id\": workflow_id,\n            \"prp_file\": state.get(\"prp_file\", \"unknown\"),\n            \"phase\": state.get(\"phase\", \"unknown\"),\n            \"workflow_status\": state.get(\"workflow_status\", \"in_progress\"),\n            \"gates_passed\": state.get(\"gates_passed\", []),\n            \"gates_failed\": state.get(\"gates_failed\", {}),\n            \"consecutive_failures\": state.get(\"consecutive_failures\", 0),\n            \"circuit_breaker_active\": state.get(\"circuit_breaker_active\", False),\n            \"started_at\": state.get(\"started_at\"),\n            \"last_updated\": state.get(\"last_updated\")\n        }\n\n    def _write_debug_cache(self, workflow_id: str, state: Dict[str, Any]):\n        \"\"\"\n        Write state to debug cache (temporary).\n\n        Args:\n            workflow_id: Workflow identifier\n            state: State to cache\n        \"\"\"\n        if not self.cache_dir:\n            return\n\n        cache_file = self.cache_dir / f\"{workflow_id}.json\"\n\n        try:\n            # Serialize state (handle datetime objects)\n            serializable_state = self._make_serializable(state)\n\n            with open(cache_file, 'w') as f:\n                json.dump(serializable_state, f, indent=2)\n\n            logger.debug(f\"Debug cache written: {cache_file}\")\n        except Exception as e:\n            logger.error(f\"Error writing debug cache: {e}\")\n\n    def _make_serializable(self, obj: Any) -> Any:\n        \"\"\"\n        Make object JSON serializable.\n\n        Args:\n            obj: Object to serialize\n\n        Returns:\n            JSON-serializable version\n        \"\"\"\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        elif isinstance(obj, dict):\n            return {k: self._make_serializable(v) for k, v in obj.items()}\n        elif isinstance(obj, (list, tuple)):\n            return [self._make_serializable(item) for item in obj]\n        else:\n            return obj\n"},"tool_response":{"type":"create","filePath":"/home/thomas/Repositories/LangChangeWorkflows/langgraph/utils/state_persistence.py","content":"\"\"\"\nState Persistence\n\nHandles ephemeral state storage for LangGraph workflows.\nState is session-only and never persisted to permanent storage for privacy.\n\nKey Features:\n- Session-only state storage (memory)\n- Optional disk cache for debugging (auto-deleted)\n- State snapshots for workflow inspection\n- Automatic cleanup on workflow completion\n\"\"\"\n\nimport logging\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime\nimport json\nfrom pathlib import Path\n\nlogger = logging.getLogger(__name__)\n\n\nclass StatePersistence:\n    \"\"\"\n    Manages ephemeral state persistence for workflows.\n\n    Privacy-First Design:\n    - State stored in memory only\n    - Optional temp disk cache for debugging (auto-cleanup)\n    - No sensitive data persisted beyond session\n    - Complete cleanup on workflow end\n    \"\"\"\n\n    def __init__(self, enable_debug_cache: bool = False):\n        \"\"\"\n        Initialize state persistence.\n\n        Args:\n            enable_debug_cache: Enable temporary disk cache for debugging\n        \"\"\"\n        self.enable_debug_cache = enable_debug_cache\n        self.cache_dir = Path(\".langgraph/state_cache\") if enable_debug_cache else None\n\n        if self.cache_dir:\n            self.cache_dir.mkdir(parents=True, exist_ok=True)\n            logger.warning(\"Debug cache enabled - state will be temporarily persisted to disk\")\n\n        self.active_states: Dict[str, Dict[str, Any]] = {}\n\n        logger.info(f\"StatePersistence initialized (debug_cache: {enable_debug_cache})\")\n\n    def save_state(self, state: Dict[str, Any]):\n        \"\"\"\n        Save workflow state (ephemeral).\n\n        Args:\n            state: Workflow state to save\n        \"\"\"\n        workflow_id = state.get(\"workflow_id\", \"unknown\")\n\n        # Store in memory\n        self.active_states[workflow_id] = {\n            **state,\n            \"last_updated\": datetime.now().isoformat()\n        }\n\n        # Optional debug cache\n        if self.enable_debug_cache and self.cache_dir:\n            self._write_debug_cache(workflow_id, state)\n\n        logger.debug(f\"State saved for workflow: {workflow_id}\")\n\n    def load_state(self, workflow_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Load workflow state from memory.\n\n        Args:\n            workflow_id: Workflow identifier\n\n        Returns:\n            Workflow state or None if not found\n        \"\"\"\n        state = self.active_states.get(workflow_id)\n\n        if state:\n            logger.debug(f\"State loaded for workflow: {workflow_id}\")\n        else:\n            logger.warning(f\"No state found for workflow: {workflow_id}\")\n\n        return state\n\n    def get_snapshot(self, workflow_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Get read-only snapshot of workflow state.\n\n        Args:\n            workflow_id: Workflow identifier\n\n        Returns:\n            Deep copy of state for inspection\n        \"\"\"\n        state = self.active_states.get(workflow_id)\n\n        if not state:\n            return None\n\n        # Return deep copy to prevent modification\n        import copy\n        return copy.deepcopy(state)\n\n    def cleanup_workflow(self, workflow_id: str):\n        \"\"\"\n        Clean up all state for completed workflow.\n\n        Args:\n            workflow_id: Workflow identifier\n        \"\"\"\n        # Remove from memory\n        if workflow_id in self.active_states:\n            del self.active_states[workflow_id]\n\n        # Remove debug cache if exists\n        if self.enable_debug_cache and self.cache_dir:\n            cache_file = self.cache_dir / f\"{workflow_id}.json\"\n            if cache_file.exists():\n                cache_file.unlink()\n\n        logger.info(f\"Cleaned up state for workflow: {workflow_id}\")\n\n    def cleanup_all(self):\n        \"\"\"\n        Clean up all active states (emergency cleanup).\n        \"\"\"\n        workflow_count = len(self.active_states)\n\n        # Clear memory\n        self.active_states.clear()\n\n        # Clear debug cache\n        if self.enable_debug_cache and self.cache_dir:\n            for cache_file in self.cache_dir.glob(\"*.json\"):\n                cache_file.unlink()\n\n        logger.info(f\"Cleaned up all states ({workflow_count} workflows)\")\n\n    def list_active_workflows(self) -> list[str]:\n        \"\"\"\n        List all active workflow IDs.\n\n        Returns:\n            List of workflow identifiers\n        \"\"\"\n        return list(self.active_states.keys())\n\n    def get_workflow_summary(self, workflow_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Get summary of workflow state (non-sensitive fields only).\n\n        Args:\n            workflow_id: Workflow identifier\n\n        Returns:\n            Summary dict with workflow status, gates, etc.\n        \"\"\"\n        state = self.active_states.get(workflow_id)\n\n        if not state:\n            return None\n\n        return {\n            \"workflow_id\": workflow_id,\n            \"prp_file\": state.get(\"prp_file\", \"unknown\"),\n            \"phase\": state.get(\"phase\", \"unknown\"),\n            \"workflow_status\": state.get(\"workflow_status\", \"in_progress\"),\n            \"gates_passed\": state.get(\"gates_passed\", []),\n            \"gates_failed\": state.get(\"gates_failed\", {}),\n            \"consecutive_failures\": state.get(\"consecutive_failures\", 0),\n            \"circuit_breaker_active\": state.get(\"circuit_breaker_active\", False),\n            \"started_at\": state.get(\"started_at\"),\n            \"last_updated\": state.get(\"last_updated\")\n        }\n\n    def _write_debug_cache(self, workflow_id: str, state: Dict[str, Any]):\n        \"\"\"\n        Write state to debug cache (temporary).\n\n        Args:\n            workflow_id: Workflow identifier\n            state: State to cache\n        \"\"\"\n        if not self.cache_dir:\n            return\n\n        cache_file = self.cache_dir / f\"{workflow_id}.json\"\n\n        try:\n            # Serialize state (handle datetime objects)\n            serializable_state = self._make_serializable(state)\n\n            with open(cache_file, 'w') as f:\n                json.dump(serializable_state, f, indent=2)\n\n            logger.debug(f\"Debug cache written: {cache_file}\")\n        except Exception as e:\n            logger.error(f\"Error writing debug cache: {e}\")\n\n    def _make_serializable(self, obj: Any) -> Any:\n        \"\"\"\n        Make object JSON serializable.\n\n        Args:\n            obj: Object to serialize\n\n        Returns:\n            JSON-serializable version\n        \"\"\"\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        elif isinstance(obj, dict):\n            return {k: self._make_serializable(v) for k, v in obj.items()}\n        elif isinstance(obj, (list, tuple)):\n            return [self._make_serializable(item) for item in obj]\n        else:\n            return obj\n","structuredPatch":[]}}
