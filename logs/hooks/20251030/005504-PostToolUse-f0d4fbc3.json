{"session_id":"f0d4fbc3-a5b1-443e-8264-7550e32cfe6a","transcript_path":"/home/thomas/.claude/projects/-home-thomas-Repositories-LangChangeWorkflows/f0d4fbc3-a5b1-443e-8264-7550e32cfe6a.jsonl","cwd":"/home/thomas/Repositories/LangChangeWorkflows","permission_mode":"acceptEdits","hook_event_name":"PostToolUse","tool_name":"Write","tool_input":{"file_path":"/home/thomas/Repositories/LangChangeWorkflows/LEARNING_GUIDE.md","content":"# LangGraph PRP Workflow - Complete Learning Guide\n\nThis guide will teach you how LangGraph works from first principles, using your PRP workflow as the example.\n\n## Part 1: The Big Picture\n\n### What Problem Are We Solving?\n\nYour **POC scripts** (draft-001.py → draft-004.py) work like this:\n\n```\n[User Request]\n    → draft-001.py (decompose to tasks)\n    → draft-002.py (Q&A with architect)\n    → draft-003.py (recommended agents)\n    → draft-004.py (consolidate results)\n    → [Final PRP]\n```\n\n**Problems with this approach:**\n1. ❌ No state persistence - if script crashes, start over\n2. ❌ No retry logic - manual re-runs needed\n3. ❌ High API costs - rebuilding context every time\n4. ❌ Hard to add conditional logic - need custom code for every branch\n5. ❌ No visualization - can't see where you are in the process\n\n### What LangGraph Solves\n\n```\n[User Request]\n    ↓\n[LangGraph StateGraph]\n    ├─ State Management (automatic checkpointing)\n    ├─ Retry Logic (3-strike rule built-in)\n    ├─ Context Caching (40% cost savings)\n    ├─ Conditional Routing (declarative branching)\n    └─ Visual Inspection (see workflow state anytime)\n    ↓\n[Final PRP]\n```\n\n**LangGraph gives you:**\n- ✅ Automatic state management\n- ✅ Built-in retry logic with circuit breakers\n- ✅ Context optimization (caching)\n- ✅ Declarative workflow definition\n- ✅ Resume capability (pause/continue)\n\n---\n\n## Part 2: State Machines 101\n\n### The Core Concept\n\nA **state machine** is like a flowchart that remembers where it is:\n\n```\n[Start] → [Process] → [Check Result] → [Success/Retry] → [End]\n           ↑__________________________|\n                  (loop on failure)\n```\n\n**Key Components:**\n\n1. **State** - Current data and position\n2. **Nodes** - Processing steps\n3. **Edges** - Transitions between nodes\n4. **Conditions** - Decide which path to take\n\n### Your POC vs LangGraph State Machine\n\n**Your POC (draft-003.py):**\n```python\n# Manual state tracking\nbatch = client.messages.batches.create(requests=reqs)\nwhile True:  # Manual polling\n    b = client.messages.batches.retrieve(batch.id)\n    if b.processing_status in (\"ended\", \"failed\", \"expired\"):\n        break\n    time.sleep(2)  # Manual retry logic\nresults = list(client.messages.batches.results(batch.id))\n# Process results, save to files... (manual)\n```\n\n**LangGraph version:**\n```python\n# Automatic state management\nworkflow = BasePRPWorkflow()\nresult = workflow.execute(prp_file=\"feature.md\")\n# State is automatically managed, retries are automatic,\n# checkpoints are automatic, costs are tracked\n```\n\nAll the complexity is handled by the framework!\n\n---\n\n## Part 3: LangGraph Architecture\n\n### The StateGraph\n\nThink of StateGraph as a **flowchart that executes itself**:\n\n```\n            [Initialize]\n                 ↓\n          [Gate 2: Coverage]\n            ↙       ↘\n    [Success]    [Failed]\n        ↓            ↓\n    [Complete]  [Retry?] ← (tracks attempts)\n                    ↓\n              [Try Again] → back to Gate 2\n                    ↓ (if 3 failures)\n           [Consult Specialist]\n                    ↓\n              [Try Again] → back to Gate 2\n                    ↓ (if 15 total failures)\n            [Circuit Breaker]\n                    ↓\n              [Workflow Failed]\n```\n\n### The State Object\n\n**PRPState** - The data that flows through the workflow:\n\n```python\n{\n    \"prp_file\": \"feature.md\",\n    \"workflow_id\": \"prp-20251030-abc123\",\n    \"gates_passed\": [\"gate_2_coverage\"],  # Which gates succeeded\n    \"gates_failed\": {\"gate_3_mock\": 2},   # Which failed and retry count\n    \"consecutive_failures\": 0,            # Circuit breaker counter\n    \"cost_tracking\": {                    # Cost per gate\n        \"gate_2_coverage\": 0.03\n    },\n    \"current_gate\": \"gate_2_coverage\",    # Where we are now\n    \"circuit_breaker_active\": False\n}\n```\n\nThis state object:\n- ✅ Automatically persists between nodes\n- ✅ Can be inspected at any time\n- ✅ Survives crashes (with checkpointing)\n- ✅ Tracks all workflow history\n\n---\n\n## Part 4: How Your Workflow Works\n\n### File Structure\n\n```\nprp_langgraph/\n├── workflows/\n│   └── base_prp_workflow.py    ← Main workflow definition\n├── nodes/\n│   └── gates/\n│       └── gate2_coverage.py   ← Gate validation logic\n├── schemas/\n│   └── prp_state.py            ← State definition\n└── utils/\n    ├── context_optimizer.py    ← Cost savings (caching)\n    ├── agent_coordinator.py    ← Multi-agent orchestration\n    └── state_persistence.py    ← State management\n```\n\n### Step-by-Step Execution Flow\n\n**1. Initialize Workflow**\n\n```python\nworkflow = BasePRPWorkflow()\n```\n\nThis:\n- Loads configuration from YAML\n- Creates StateGraph with nodes and edges\n- Sets up context optimizer for caching\n- Prepares agent coordinator\n\n**2. Execute Workflow**\n\n```python\nresult = workflow.execute(prp_file=\"feature.md\", initial_state={...})\n```\n\nThis:\n- Creates initial PRPState\n- Enters the graph at \"initialize\" node\n- Flows through nodes based on edges\n- Returns final state when reaching END\n\n**3. Node Execution (Example: Gate 2)**\n\n```python\ndef validate_gate_2(self, state: PRPState) -> PRPState:\n    # 1. Extract current state\n    gate_id = \"gate_2_coverage\"\n    retry_count = state.get(\"gates_failed\", {}).get(gate_id, 0)\n\n    # 2. Run validation\n    result = validate_coverage_gate(state, config, context_optimizer)\n\n    # 3. Update state\n    if result[\"passed\"]:\n        state[\"gates_passed\"] = state.get(\"gates_passed\", []) + [gate_id]\n        state[\"consecutive_failures\"] = 0  # Reset on success\n    else:\n        state[\"gates_failed\"][gate_id] = retry_count + 1\n        state[\"consecutive_failures\"] += 1\n\n    # 4. Return updated state (flows to next node)\n    return state\n```\n\n**4. Conditional Routing**\n\n```python\ndef route_gate_result(self, state: PRPState) -> str:\n    # Decide which node to go to next based on state\n    if state[\"current_validation_result\"][\"passed\"]:\n        return \"success\"  # Go to workflow_success node\n    elif state[\"consecutive_failures\"] >= 15:\n        return \"circuit_breaker\"  # Go to circuit_breaker node\n    else:\n        return \"retry\"  # Go to handle_failure node\n```\n\nThe graph automatically follows these routes!\n\n---\n\n## Part 5: Comparison to Your POC Scripts\n\n### draft-001.py → LangGraph Equivalent\n\n**Your POC:**\n```python\n# draft-001.py - Manual batch submission\nbatch = client.messages.batches.create(requests=panel_requests)\nwhile True:\n    b = client.messages.batches.retrieve(batch.id)\n    if b.processing_status in (\"ended\", \"failed\", \"expired\"):\n        break\n    time.sleep(2)\n```\n\n**LangGraph:**\n```python\n# Workflow node - automatic execution\ndef execute_panel_agents(self, state: PRPState) -> PRPState:\n    agents = state[\"panel_agents\"]  # From state\n    results = self.agent_coordinator.run_panel(agents, state)\n    state[\"panel_results\"] = results\n    return state  # Automatically moves to next node\n```\n\n**Key Differences:**\n- ❌ POC: Manual polling loop\n- ✅ LangGraph: Automatic execution, state flows naturally\n- ❌ POC: No retry logic\n- ✅ LangGraph: Built-in retry with 3-strike rule\n- ❌ POC: State in variables/files\n- ✅ LangGraph: State object with automatic persistence\n\n### draft-004.py → LangGraph Equivalent\n\n**Your POC:**\n```python\n# draft-004.py - Manual consolidation\nitems = []\nfor p in files:\n    obj = _read_json(p)\n    items.append(obj)\n\n# Manual retry on failure\nif not _valid(payload):\n    # Build repair prompt manually\n    repair_user_text = _build_repair_prompt(payload, combined, template_text)\n    # Submit repair batch manually\n    rep_batch = client.messages.batches.create(requests=[repair_req])\n    # Poll manually again...\n```\n\n**LangGraph:**\n```python\n# Consolidation node with automatic retry\ndef consolidate_drafts(self, state: PRPState) -> PRPState:\n    drafts = state[\"draft_results\"]\n\n    consolidated = self.agent_coordinator.consolidate(\n        drafts=drafts,\n        template=state[\"template\"],\n        context_optimizer=self.context_optimizer  # Automatic caching\n    )\n\n    state[\"consolidated_prp\"] = consolidated\n    return state\n\n# Retry logic is automatic via conditional edges\nworkflow.add_conditional_edges(\n    \"consolidate_drafts\",\n    lambda state: \"retry\" if not state[\"consolidated_prp\"][\"valid\"] else \"success\"\n)\n```\n\n**Key Differences:**\n- ❌ POC: Manual file reading and processing\n- ✅ LangGraph: State contains everything, automatic flow\n- ❌ POC: Custom repair logic with separate batch\n- ✅ LangGraph: Declarative retry via conditional edges\n- ❌ POC: No cost tracking\n- ✅ LangGraph: Automatic cost tracking with caching\n\n---\n\n## Part 6: Cost Optimization Deep-Dive\n\n### How Context Caching Works\n\n**Without LangGraph (Your POC):**\n```python\n# Every API call rebuilds full context\nsystem_text = load_agent_text(\"agent\")  # Full agent prompt\nuser_text = build_prompt(feature)        # Full feature description\n\n# Call 1: ~2000 tokens → $0.03\nresponse1 = client.messages.create(system=[{\"text\": system_text}], messages=[{\"text\": user_text}])\n\n# Call 2: ~2000 tokens → $0.03 (no caching, full context again)\nresponse2 = client.messages.create(system=[{\"text\": system_text}], messages=[{\"text\": user_text}])\n\n# Total: $0.06\n```\n\n**With LangGraph Context Optimizer:**\n```python\n# Call 1: ~2000 tokens → $0.03\ncached_context = context_optimizer.cache_context(\"agent\", system_text)\nresponse1 = client.messages.create(system=cached_context, messages=[{\"text\": user_text}])\n\n# Call 2: ~500 tokens → $0.01 (75% savings! Uses cache)\nresponse2 = client.messages.create(system=cached_context, messages=[{\"text\": user_text}])\n\n# Total: $0.04 (40% savings)\n```\n\nThe `context_optimizer.py` automatically:\n1. Caches agent prompts\n2. Caches file contents\n3. Shares context across retries\n4. Tracks cache hit rates\n5. Calculates cost savings\n\n### Cost Tracking in Action\n\n```python\n# After workflow completes:\nresult = workflow.execute(prp_file=\"feature.md\")\n\ncost_tracking = result[\"cost_tracking\"]\n# {\n#     \"gate_2_coverage\": 0.03,\n#     \"gate_3_mock\": 0.015,\n#     \"total\": 0.045\n# }\n\ncache_stats = workflow.context_optimizer.get_cache_stats()\n# {\n#     \"cache_hits\": 5,\n#     \"cache_misses\": 2,\n#     \"hit_rate_percentage\": 71.4,\n#     \"estimated_savings_usd\": 0.10\n# }\n```\n\n---\n\n## Part 7: Extension and Customization\n\n### Adding a New Gate (Example: Gate 7 - Privacy Validation)\n\n**Step 1: Create the node function**\n\n```python\n# prp_langgraph/nodes/gates/gate7_privacy.py\n\ndef validate_privacy_gate(state, config, context_optimizer):\n    \"\"\"Validate zero PII in production code.\"\"\"\n\n    # Scan for PII patterns\n    pii_patterns = [\"ssn\", \"credit_card\", \"email\", \"phone\"]\n    violations = scan_for_patterns(state[\"project_path\"], pii_patterns)\n\n    passed = len(violations) == 0\n\n    return {\n        \"gate_id\": \"gate_7_privacy\",\n        \"passed\": passed,\n        \"message\": f\"Found {len(violations)} PII violations\" if not passed else \"No PII found\",\n        \"details\": {\"violations\": violations},\n        \"cost\": 0.02,\n        \"tokens_used\": 1500\n    }\n```\n\n**Step 2: Add to workflow**\n\n```python\n# Custom workflow extending base\nclass OrgCashWorkflow(BasePRPWorkflow):\n    def build_graph(self):\n        workflow = super().build_graph()  # Get base graph\n\n        # Add your custom gate\n        workflow.add_node(\"gate_7_privacy\", self.validate_gate_7)\n\n        # Add edges\n        workflow.add_conditional_edges(\n            \"gate_6_production_ready\",  # After gate 6\n            lambda state: \"gate_7_privacy\" if \"gate_6\" in state[\"gates_passed\"]\n                         else \"handle_failure\"\n        )\n\n        workflow.add_conditional_edges(\n            \"gate_7_privacy\",\n            self.route_gate_result,  # Reuse existing routing\n            {\"success\": \"workflow_success\", \"retry\": \"handle_failure\"}\n        )\n\n        return workflow\n\n    def validate_gate_7(self, state):\n        result = validate_privacy_gate(state, self.config, self.context_optimizer)\n        # ... update state like other gates\n        return state\n```\n\n**Step 3: Use your custom workflow**\n\n```python\nworkflow = OrgCashWorkflow()  # Your extended version\nresult = workflow.execute(prp_file=\"feature.md\")\n```\n\n### Configuration Override\n\n```yaml\n# .langgraph/config/gates.yaml in your project\nextends: \"~/.claude/langgraph/config/default_gates.yaml\"\n\ngates:\n  # Add your custom gate\n  gate_7_privacy:\n    enabled: true\n    blocking: true\n    pii_patterns:\n      - \"ssn\"\n      - \"credit_card\"\n```\n\n---\n\n## Part 8: Debugging and Inspection\n\n### View Current State\n\n```python\nfrom prp_langgraph.utils.state_persistence import StatePersistence\n\npersistence = StatePersistence()\n\n# List all active workflows\nworkflows = persistence.list_active_workflows()\nprint(f\"Active: {workflows}\")\n\n# Get state snapshot\nstate = persistence.get_snapshot(workflow_id=\"prp-20251030-abc123\")\nprint(f\"Current gate: {state['current_gate']}\")\nprint(f\"Gates passed: {state['gates_passed']}\")\nprint(f\"Consecutive failures: {state['consecutive_failures']}\")\n```\n\n### Enable Debug Mode\n\n```python\nimport logging\n\nlogging.basicConfig(level=logging.DEBUG)\n\nworkflow = BasePRPWorkflow()\nresult = workflow.execute(prp_file=\"feature.md\")\n\n# Logs show:\n# DEBUG: Initializing workflow for PRP: feature.md\n# DEBUG: Validating Gate 2: Test Coverage\n# DEBUG: Gate 2 PASSED - Coverage: 100%\n# INFO: Workflow completed successfully!\n```\n\n### Inspect Cache Performance\n\n```python\noptimizer = workflow.context_optimizer\nstats = optimizer.get_cache_stats()\n\nprint(f\"Cache hits: {stats['cache_hits']}\")\nprint(f\"Cache misses: {stats['cache_misses']}\")\nprint(f\"Hit rate: {stats['hit_rate_percentage']}%\")\nprint(f\"Savings: ${stats['estimated_cost_savings_usd']}\")\n```\n\n---\n\n## Next Steps\n\nNow that you understand the concepts, try:\n\n1. **Read the interactive walkthrough**: `examples/learning/interactive_walkthrough.py`\n2. **See the visual diagrams**: `docs/architecture_diagrams.md`\n3. **Compare POC side-by-side**: `docs/POC_COMPARISON.md`\n4. **Run on a real project**: `auto_detect_runner.py`\n\nThe key insight: **LangGraph turns your manual workflow scripts into a declarative state machine with automatic retry, caching, and state management built-in.**\n"},"tool_response":{"type":"create","filePath":"/home/thomas/Repositories/LangChangeWorkflows/LEARNING_GUIDE.md","content":"# LangGraph PRP Workflow - Complete Learning Guide\n\nThis guide will teach you how LangGraph works from first principles, using your PRP workflow as the example.\n\n## Part 1: The Big Picture\n\n### What Problem Are We Solving?\n\nYour **POC scripts** (draft-001.py → draft-004.py) work like this:\n\n```\n[User Request]\n    → draft-001.py (decompose to tasks)\n    → draft-002.py (Q&A with architect)\n    → draft-003.py (recommended agents)\n    → draft-004.py (consolidate results)\n    → [Final PRP]\n```\n\n**Problems with this approach:**\n1. ❌ No state persistence - if script crashes, start over\n2. ❌ No retry logic - manual re-runs needed\n3. ❌ High API costs - rebuilding context every time\n4. ❌ Hard to add conditional logic - need custom code for every branch\n5. ❌ No visualization - can't see where you are in the process\n\n### What LangGraph Solves\n\n```\n[User Request]\n    ↓\n[LangGraph StateGraph]\n    ├─ State Management (automatic checkpointing)\n    ├─ Retry Logic (3-strike rule built-in)\n    ├─ Context Caching (40% cost savings)\n    ├─ Conditional Routing (declarative branching)\n    └─ Visual Inspection (see workflow state anytime)\n    ↓\n[Final PRP]\n```\n\n**LangGraph gives you:**\n- ✅ Automatic state management\n- ✅ Built-in retry logic with circuit breakers\n- ✅ Context optimization (caching)\n- ✅ Declarative workflow definition\n- ✅ Resume capability (pause/continue)\n\n---\n\n## Part 2: State Machines 101\n\n### The Core Concept\n\nA **state machine** is like a flowchart that remembers where it is:\n\n```\n[Start] → [Process] → [Check Result] → [Success/Retry] → [End]\n           ↑__________________________|\n                  (loop on failure)\n```\n\n**Key Components:**\n\n1. **State** - Current data and position\n2. **Nodes** - Processing steps\n3. **Edges** - Transitions between nodes\n4. **Conditions** - Decide which path to take\n\n### Your POC vs LangGraph State Machine\n\n**Your POC (draft-003.py):**\n```python\n# Manual state tracking\nbatch = client.messages.batches.create(requests=reqs)\nwhile True:  # Manual polling\n    b = client.messages.batches.retrieve(batch.id)\n    if b.processing_status in (\"ended\", \"failed\", \"expired\"):\n        break\n    time.sleep(2)  # Manual retry logic\nresults = list(client.messages.batches.results(batch.id))\n# Process results, save to files... (manual)\n```\n\n**LangGraph version:**\n```python\n# Automatic state management\nworkflow = BasePRPWorkflow()\nresult = workflow.execute(prp_file=\"feature.md\")\n# State is automatically managed, retries are automatic,\n# checkpoints are automatic, costs are tracked\n```\n\nAll the complexity is handled by the framework!\n\n---\n\n## Part 3: LangGraph Architecture\n\n### The StateGraph\n\nThink of StateGraph as a **flowchart that executes itself**:\n\n```\n            [Initialize]\n                 ↓\n          [Gate 2: Coverage]\n            ↙       ↘\n    [Success]    [Failed]\n        ↓            ↓\n    [Complete]  [Retry?] ← (tracks attempts)\n                    ↓\n              [Try Again] → back to Gate 2\n                    ↓ (if 3 failures)\n           [Consult Specialist]\n                    ↓\n              [Try Again] → back to Gate 2\n                    ↓ (if 15 total failures)\n            [Circuit Breaker]\n                    ↓\n              [Workflow Failed]\n```\n\n### The State Object\n\n**PRPState** - The data that flows through the workflow:\n\n```python\n{\n    \"prp_file\": \"feature.md\",\n    \"workflow_id\": \"prp-20251030-abc123\",\n    \"gates_passed\": [\"gate_2_coverage\"],  # Which gates succeeded\n    \"gates_failed\": {\"gate_3_mock\": 2},   # Which failed and retry count\n    \"consecutive_failures\": 0,            # Circuit breaker counter\n    \"cost_tracking\": {                    # Cost per gate\n        \"gate_2_coverage\": 0.03\n    },\n    \"current_gate\": \"gate_2_coverage\",    # Where we are now\n    \"circuit_breaker_active\": False\n}\n```\n\nThis state object:\n- ✅ Automatically persists between nodes\n- ✅ Can be inspected at any time\n- ✅ Survives crashes (with checkpointing)\n- ✅ Tracks all workflow history\n\n---\n\n## Part 4: How Your Workflow Works\n\n### File Structure\n\n```\nprp_langgraph/\n├── workflows/\n│   └── base_prp_workflow.py    ← Main workflow definition\n├── nodes/\n│   └── gates/\n│       └── gate2_coverage.py   ← Gate validation logic\n├── schemas/\n│   └── prp_state.py            ← State definition\n└── utils/\n    ├── context_optimizer.py    ← Cost savings (caching)\n    ├── agent_coordinator.py    ← Multi-agent orchestration\n    └── state_persistence.py    ← State management\n```\n\n### Step-by-Step Execution Flow\n\n**1. Initialize Workflow**\n\n```python\nworkflow = BasePRPWorkflow()\n```\n\nThis:\n- Loads configuration from YAML\n- Creates StateGraph with nodes and edges\n- Sets up context optimizer for caching\n- Prepares agent coordinator\n\n**2. Execute Workflow**\n\n```python\nresult = workflow.execute(prp_file=\"feature.md\", initial_state={...})\n```\n\nThis:\n- Creates initial PRPState\n- Enters the graph at \"initialize\" node\n- Flows through nodes based on edges\n- Returns final state when reaching END\n\n**3. Node Execution (Example: Gate 2)**\n\n```python\ndef validate_gate_2(self, state: PRPState) -> PRPState:\n    # 1. Extract current state\n    gate_id = \"gate_2_coverage\"\n    retry_count = state.get(\"gates_failed\", {}).get(gate_id, 0)\n\n    # 2. Run validation\n    result = validate_coverage_gate(state, config, context_optimizer)\n\n    # 3. Update state\n    if result[\"passed\"]:\n        state[\"gates_passed\"] = state.get(\"gates_passed\", []) + [gate_id]\n        state[\"consecutive_failures\"] = 0  # Reset on success\n    else:\n        state[\"gates_failed\"][gate_id] = retry_count + 1\n        state[\"consecutive_failures\"] += 1\n\n    # 4. Return updated state (flows to next node)\n    return state\n```\n\n**4. Conditional Routing**\n\n```python\ndef route_gate_result(self, state: PRPState) -> str:\n    # Decide which node to go to next based on state\n    if state[\"current_validation_result\"][\"passed\"]:\n        return \"success\"  # Go to workflow_success node\n    elif state[\"consecutive_failures\"] >= 15:\n        return \"circuit_breaker\"  # Go to circuit_breaker node\n    else:\n        return \"retry\"  # Go to handle_failure node\n```\n\nThe graph automatically follows these routes!\n\n---\n\n## Part 5: Comparison to Your POC Scripts\n\n### draft-001.py → LangGraph Equivalent\n\n**Your POC:**\n```python\n# draft-001.py - Manual batch submission\nbatch = client.messages.batches.create(requests=panel_requests)\nwhile True:\n    b = client.messages.batches.retrieve(batch.id)\n    if b.processing_status in (\"ended\", \"failed\", \"expired\"):\n        break\n    time.sleep(2)\n```\n\n**LangGraph:**\n```python\n# Workflow node - automatic execution\ndef execute_panel_agents(self, state: PRPState) -> PRPState:\n    agents = state[\"panel_agents\"]  # From state\n    results = self.agent_coordinator.run_panel(agents, state)\n    state[\"panel_results\"] = results\n    return state  # Automatically moves to next node\n```\n\n**Key Differences:**\n- ❌ POC: Manual polling loop\n- ✅ LangGraph: Automatic execution, state flows naturally\n- ❌ POC: No retry logic\n- ✅ LangGraph: Built-in retry with 3-strike rule\n- ❌ POC: State in variables/files\n- ✅ LangGraph: State object with automatic persistence\n\n### draft-004.py → LangGraph Equivalent\n\n**Your POC:**\n```python\n# draft-004.py - Manual consolidation\nitems = []\nfor p in files:\n    obj = _read_json(p)\n    items.append(obj)\n\n# Manual retry on failure\nif not _valid(payload):\n    # Build repair prompt manually\n    repair_user_text = _build_repair_prompt(payload, combined, template_text)\n    # Submit repair batch manually\n    rep_batch = client.messages.batches.create(requests=[repair_req])\n    # Poll manually again...\n```\n\n**LangGraph:**\n```python\n# Consolidation node with automatic retry\ndef consolidate_drafts(self, state: PRPState) -> PRPState:\n    drafts = state[\"draft_results\"]\n\n    consolidated = self.agent_coordinator.consolidate(\n        drafts=drafts,\n        template=state[\"template\"],\n        context_optimizer=self.context_optimizer  # Automatic caching\n    )\n\n    state[\"consolidated_prp\"] = consolidated\n    return state\n\n# Retry logic is automatic via conditional edges\nworkflow.add_conditional_edges(\n    \"consolidate_drafts\",\n    lambda state: \"retry\" if not state[\"consolidated_prp\"][\"valid\"] else \"success\"\n)\n```\n\n**Key Differences:**\n- ❌ POC: Manual file reading and processing\n- ✅ LangGraph: State contains everything, automatic flow\n- ❌ POC: Custom repair logic with separate batch\n- ✅ LangGraph: Declarative retry via conditional edges\n- ❌ POC: No cost tracking\n- ✅ LangGraph: Automatic cost tracking with caching\n\n---\n\n## Part 6: Cost Optimization Deep-Dive\n\n### How Context Caching Works\n\n**Without LangGraph (Your POC):**\n```python\n# Every API call rebuilds full context\nsystem_text = load_agent_text(\"agent\")  # Full agent prompt\nuser_text = build_prompt(feature)        # Full feature description\n\n# Call 1: ~2000 tokens → $0.03\nresponse1 = client.messages.create(system=[{\"text\": system_text}], messages=[{\"text\": user_text}])\n\n# Call 2: ~2000 tokens → $0.03 (no caching, full context again)\nresponse2 = client.messages.create(system=[{\"text\": system_text}], messages=[{\"text\": user_text}])\n\n# Total: $0.06\n```\n\n**With LangGraph Context Optimizer:**\n```python\n# Call 1: ~2000 tokens → $0.03\ncached_context = context_optimizer.cache_context(\"agent\", system_text)\nresponse1 = client.messages.create(system=cached_context, messages=[{\"text\": user_text}])\n\n# Call 2: ~500 tokens → $0.01 (75% savings! Uses cache)\nresponse2 = client.messages.create(system=cached_context, messages=[{\"text\": user_text}])\n\n# Total: $0.04 (40% savings)\n```\n\nThe `context_optimizer.py` automatically:\n1. Caches agent prompts\n2. Caches file contents\n3. Shares context across retries\n4. Tracks cache hit rates\n5. Calculates cost savings\n\n### Cost Tracking in Action\n\n```python\n# After workflow completes:\nresult = workflow.execute(prp_file=\"feature.md\")\n\ncost_tracking = result[\"cost_tracking\"]\n# {\n#     \"gate_2_coverage\": 0.03,\n#     \"gate_3_mock\": 0.015,\n#     \"total\": 0.045\n# }\n\ncache_stats = workflow.context_optimizer.get_cache_stats()\n# {\n#     \"cache_hits\": 5,\n#     \"cache_misses\": 2,\n#     \"hit_rate_percentage\": 71.4,\n#     \"estimated_savings_usd\": 0.10\n# }\n```\n\n---\n\n## Part 7: Extension and Customization\n\n### Adding a New Gate (Example: Gate 7 - Privacy Validation)\n\n**Step 1: Create the node function**\n\n```python\n# prp_langgraph/nodes/gates/gate7_privacy.py\n\ndef validate_privacy_gate(state, config, context_optimizer):\n    \"\"\"Validate zero PII in production code.\"\"\"\n\n    # Scan for PII patterns\n    pii_patterns = [\"ssn\", \"credit_card\", \"email\", \"phone\"]\n    violations = scan_for_patterns(state[\"project_path\"], pii_patterns)\n\n    passed = len(violations) == 0\n\n    return {\n        \"gate_id\": \"gate_7_privacy\",\n        \"passed\": passed,\n        \"message\": f\"Found {len(violations)} PII violations\" if not passed else \"No PII found\",\n        \"details\": {\"violations\": violations},\n        \"cost\": 0.02,\n        \"tokens_used\": 1500\n    }\n```\n\n**Step 2: Add to workflow**\n\n```python\n# Custom workflow extending base\nclass OrgCashWorkflow(BasePRPWorkflow):\n    def build_graph(self):\n        workflow = super().build_graph()  # Get base graph\n\n        # Add your custom gate\n        workflow.add_node(\"gate_7_privacy\", self.validate_gate_7)\n\n        # Add edges\n        workflow.add_conditional_edges(\n            \"gate_6_production_ready\",  # After gate 6\n            lambda state: \"gate_7_privacy\" if \"gate_6\" in state[\"gates_passed\"]\n                         else \"handle_failure\"\n        )\n\n        workflow.add_conditional_edges(\n            \"gate_7_privacy\",\n            self.route_gate_result,  # Reuse existing routing\n            {\"success\": \"workflow_success\", \"retry\": \"handle_failure\"}\n        )\n\n        return workflow\n\n    def validate_gate_7(self, state):\n        result = validate_privacy_gate(state, self.config, self.context_optimizer)\n        # ... update state like other gates\n        return state\n```\n\n**Step 3: Use your custom workflow**\n\n```python\nworkflow = OrgCashWorkflow()  # Your extended version\nresult = workflow.execute(prp_file=\"feature.md\")\n```\n\n### Configuration Override\n\n```yaml\n# .langgraph/config/gates.yaml in your project\nextends: \"~/.claude/langgraph/config/default_gates.yaml\"\n\ngates:\n  # Add your custom gate\n  gate_7_privacy:\n    enabled: true\n    blocking: true\n    pii_patterns:\n      - \"ssn\"\n      - \"credit_card\"\n```\n\n---\n\n## Part 8: Debugging and Inspection\n\n### View Current State\n\n```python\nfrom prp_langgraph.utils.state_persistence import StatePersistence\n\npersistence = StatePersistence()\n\n# List all active workflows\nworkflows = persistence.list_active_workflows()\nprint(f\"Active: {workflows}\")\n\n# Get state snapshot\nstate = persistence.get_snapshot(workflow_id=\"prp-20251030-abc123\")\nprint(f\"Current gate: {state['current_gate']}\")\nprint(f\"Gates passed: {state['gates_passed']}\")\nprint(f\"Consecutive failures: {state['consecutive_failures']}\")\n```\n\n### Enable Debug Mode\n\n```python\nimport logging\n\nlogging.basicConfig(level=logging.DEBUG)\n\nworkflow = BasePRPWorkflow()\nresult = workflow.execute(prp_file=\"feature.md\")\n\n# Logs show:\n# DEBUG: Initializing workflow for PRP: feature.md\n# DEBUG: Validating Gate 2: Test Coverage\n# DEBUG: Gate 2 PASSED - Coverage: 100%\n# INFO: Workflow completed successfully!\n```\n\n### Inspect Cache Performance\n\n```python\noptimizer = workflow.context_optimizer\nstats = optimizer.get_cache_stats()\n\nprint(f\"Cache hits: {stats['cache_hits']}\")\nprint(f\"Cache misses: {stats['cache_misses']}\")\nprint(f\"Hit rate: {stats['hit_rate_percentage']}%\")\nprint(f\"Savings: ${stats['estimated_cost_savings_usd']}\")\n```\n\n---\n\n## Next Steps\n\nNow that you understand the concepts, try:\n\n1. **Read the interactive walkthrough**: `examples/learning/interactive_walkthrough.py`\n2. **See the visual diagrams**: `docs/architecture_diagrams.md`\n3. **Compare POC side-by-side**: `docs/POC_COMPARISON.md`\n4. **Run on a real project**: `auto_detect_runner.py`\n\nThe key insight: **LangGraph turns your manual workflow scripts into a declarative state machine with automatic retry, caching, and state management built-in.**\n","structuredPatch":[]}}
